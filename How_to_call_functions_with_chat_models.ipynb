{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# How to call functions with chat models\n",
    "\n",
    "This notebook covers how to use the Chat Completions API in combination with external functions to extend the capabilities of GPT models.\n",
    "\n",
    "`tools` is an optional parameter in the Chat Completion API which can be used to provide function specifications. The purpose of this is to enable models to generate function arguments which adhere to the provided specifications. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n",
    "\n",
    "Within the `tools` parameter, if the `functions` parameter is provided then by default the model will decide when it is appropriate to use one of the functions. The API can be forced to use a specific function by setting the `tool_choice` parameter to `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}`. The API can also be forced to not use any function by setting the `tool_choice` parameter to `\"none\"`. If a function is used, the output will contain `\"finish_reason\": \"tool_calls\"` in the response, as well as a `tool_calls` object that has the name of the function and the generated function arguments.\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook contains the following 2 sections:\n",
    "\n",
    "- **How to generate function arguments:** Specify a set of functions and use the API to generate function arguments.\n",
    "- **How to call functions with model generated arguments:** Close the loop by actually executing functions with model generated arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c85e26",
   "metadata": {},
   "source": [
    "## How to generate function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip install scipy --quiet\n",
    "# !pip install tenacity --quiet\n",
    "# !pip install tiktoken --quiet\n",
    "# !pip install termcolor --quiet\n",
    "# !pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d1c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\"system\": \"red\", \"user\": \"green\", \"assistant\": \"blue\", \"function\": \"magenta\"}\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "### Basic concepts\n",
    "\n",
    "Let's create some function specifications to interface with a hypothetical weather API. We'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_n_day_weather_forecast\",\n",
    "            \"description\": \"Get an N-day weather forecast\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                    \"num_days\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The number of days to forecast\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc39899",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518d6827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Sure, can you please provide the location for which you want to know the weather?', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c999375",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c42a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_c0vee0lHG01hlEclpxd9BuDh', function=Function(arguments='{\\n  \"location\": \"Fortaleza, Brazil\",\\n  \"format\": \"celsius\"\\n}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"I'm in Fortaleza, Brazil.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d4762",
   "metadata": {},
   "source": [
    "By prompting it differently, we can get it to target the other function we've told it about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa232e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Sure, I can help you with that. Could you please specify how many days you would like the weather forecast for?', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in Fortaleza, Brazil over the next x days\"})\n",
    "chat_response = chat_completion_request(messages, tools=tools)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172ddac",
   "metadata": {},
   "source": [
    "Once again, the model is asking us for clarification because it doesn't have enough information yet. In this case it already knows the location for the forecast, but it needs to know how many days are required in the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d8a543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_faZBPChMtDhAnKWHHMppK8Fo', function=Function(arguments='{\\n  \"location\": \"Fortaleza, Brazil\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 5\\n}', name='get_n_day_weather_forecast'), type='function')]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"5 days\"})\n",
    "chat_response = chat_completion_request(messages, tools=tools)\n",
    "chat_response.choices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b758a0a",
   "metadata": {},
   "source": [
    "#### Forcing the use of specific functions or no function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f79ba",
   "metadata": {},
   "source": [
    "We can force the model to use a specific function, for example get_n_day_weather_forecast by using the function_call argument. By doing so, we force the model to make assumptions about how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559371b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OH9VX9tH2FdtnTNgAWQJtcyi', function=Function(arguments='{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 1\\n}', name='get_n_day_weather_forecast'), type='function')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this cell we force the model to use get_n_day_weather_forecast\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_n_day_weather_forecast\"}})\n",
    "chat_response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ab0f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_z8ijGSoMLS7xcaU7MjLmpRL8', function=Function(arguments='{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\"\\n}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we don't force the model to use get_n_day_weather_forecast it may not\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "chat_response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd70e48",
   "metadata": {},
   "source": [
    "We can also force the model to not use a function at all. By doing so we prevent it from producing a proper function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfe54e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\"\\n}', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me the current weather (use Celcius) for Toronto, Canada.\"})\n",
    "chat_response = chat_completion_request(messages, tools=tools, tool_choice=\"none\")\n",
    "chat_response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616353b",
   "metadata": {},
   "source": [
    "### Parallel Function Calling\n",
    "\n",
    "Newer models like gpt-4-1106-preview or gpt-3.5-turbo-1106 can call multiple functions in one turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "380eeb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_8BlkS2yvbkkpL3V1Yxc6zR6u', function=Function(arguments='{\"location\": \"San Francisco, CA\", \"format\": \"celsius\", \"num_days\": 4}', name='get_n_day_weather_forecast'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='call_vSZMy3f24wb3vtNXucpFfAbG', function=Function(arguments='{\"location\": \"Glasgow\", \"format\": \"celsius\", \"num_days\": 4}', name='get_n_day_weather_forecast'), type='function')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in San Francisco and Glasgow over the next 4 days\"})\n",
    "chat_response = chat_completion_request(messages, tools=tools, model='gpt-3.5-turbo-1106')\n",
    "\n",
    "assistant_message = chat_response.choices[0].message.tool_calls\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4482aee",
   "metadata": {},
   "source": [
    "## How to call functions with model generated arguments\n",
    "\n",
    "In our next example, we'll demonstrate how to execute functions whose inputs are model-generated, and use this to implement an agent that can answer questions for us about a database. For simplicity we'll use the [Chinook sample database](https://www.sqlitetutorial.net/sqlite-sample-database/).\n",
    "\n",
    "*Note:* SQL generation can be high-risk in a production environment since models are not perfectly reliable at generating correct SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7654fef",
   "metadata": {},
   "source": [
    "### Specifying a function to execute SQL queries\n",
    "\n",
    "First let's define some helpful utility functions to extract data from a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30f6b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"Chinook.db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abec0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6e5ea",
   "metadata": {},
   "source": [
    "Now can use these utility functions to extract a representation of the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c0104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deebbd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'table_name': 'albums', 'column_names': ['AlbumId', 'Title', 'ArtistId']},\n",
       " {'table_name': 'sqlite_sequence', 'column_names': ['name', 'seq']},\n",
       " {'table_name': 'artists', 'column_names': ['ArtistId', 'Name']},\n",
       " {'table_name': 'customers',\n",
       "  'column_names': ['CustomerId',\n",
       "   'FirstName',\n",
       "   'LastName',\n",
       "   'Company',\n",
       "   'Address',\n",
       "   'City',\n",
       "   'State',\n",
       "   'Country',\n",
       "   'PostalCode',\n",
       "   'Phone',\n",
       "   'Fax',\n",
       "   'Email',\n",
       "   'SupportRepId']},\n",
       " {'table_name': 'employees',\n",
       "  'column_names': ['EmployeeId',\n",
       "   'LastName',\n",
       "   'FirstName',\n",
       "   'Title',\n",
       "   'ReportsTo',\n",
       "   'BirthDate',\n",
       "   'HireDate',\n",
       "   'Address',\n",
       "   'City',\n",
       "   'State',\n",
       "   'Country',\n",
       "   'PostalCode',\n",
       "   'Phone',\n",
       "   'Fax',\n",
       "   'Email']},\n",
       " {'table_name': 'genres', 'column_names': ['GenreId', 'Name']},\n",
       " {'table_name': 'invoices',\n",
       "  'column_names': ['InvoiceId',\n",
       "   'CustomerId',\n",
       "   'InvoiceDate',\n",
       "   'BillingAddress',\n",
       "   'BillingCity',\n",
       "   'BillingState',\n",
       "   'BillingCountry',\n",
       "   'BillingPostalCode',\n",
       "   'Total']},\n",
       " {'table_name': 'invoice_items',\n",
       "  'column_names': ['InvoiceLineId',\n",
       "   'InvoiceId',\n",
       "   'TrackId',\n",
       "   'UnitPrice',\n",
       "   'Quantity']},\n",
       " {'table_name': 'media_types', 'column_names': ['MediaTypeId', 'Name']},\n",
       " {'table_name': 'playlists', 'column_names': ['PlaylistId', 'Name']},\n",
       " {'table_name': 'playlist_track', 'column_names': ['PlaylistId', 'TrackId']},\n",
       " {'table_name': 'tracks',\n",
       "  'column_names': ['TrackId',\n",
       "   'Name',\n",
       "   'AlbumId',\n",
       "   'MediaTypeId',\n",
       "   'GenreId',\n",
       "   'Composer',\n",
       "   'Milliseconds',\n",
       "   'Bytes',\n",
       "   'UnitPrice']},\n",
       " {'table_name': 'sqlite_stat1', 'column_names': ['tbl', 'idx', 'stat']}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_schema_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73c9ee",
   "metadata": {},
   "source": [
    "As before, we'll define a function specification for the function we'd like the API to generate arguments for. Notice that we are inserting the database schema into the function specification. This will be important for the model to know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0258813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ask_database\",\n",
    "            \"description\": \"Use this function to answer user questions about music. Input should be a fully formed SQL query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": f\"\"\"\n",
    "                                SQL query extracting info to answer the user's question.\n",
    "                                SQL should be written using this database schema:\n",
    "                                {database_schema_string}\n",
    "                                The query should be returned in plain text, not in JSON.\n",
    "                                \"\"\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08c121",
   "metadata": {},
   "source": [
    "### Executing SQL queries\n",
    "\n",
    "Now let's implement the function that will actually excute queries against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65585e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results\n",
    "\n",
    "def execute_function_call(message):\n",
    "    if message.tool_calls[0].function.name == \"ask_database\":\n",
    "        query = json.loads(message.tool_calls[0].function.arguments)[\"query\"]\n",
    "        results = ask_database(conn, query)\n",
    "    else:\n",
    "        results = f\"Error: function {message.tool_calls[0].function.name} does not exist\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38c55083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Answer user questions by generating SQL queries against the Chinook Music Database.\n",
      "\u001b[0m\n",
      "\u001b[32muser: Olá, quem sao os 5 artistas com mais músicas?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\\n  \"query\": \"SELECT artists.Name, COUNT(tracks.TrackId) AS TotalTracks FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.Name ORDER BY TotalTracks DESC LIMIT 5;\"\\n}', name='ask_database')\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Answer user questions by generating SQL queries against the Chinook Music Database.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Olá, quem sao os 5 artistas com mais músicas?\"})\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "assistant_message.content = str(assistant_message.tool_calls[0].function)\n",
    "messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content})\n",
    "if assistant_message.tool_calls:\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"tool_call_id\": assistant_message.tool_calls[0].id, \"name\": assistant_message.tool_calls[0].function.name, \"content\": results})\n",
    "pretty_print_conversation(messages)\n",
    "\n",
    "# user: Hi, who are the top 5 artists by number of tracks?\n",
    "# assistant: Function(arguments='{\\n  \"query\": \"SELECT Artist.Name, COUNT(Track.TrackId) AS TrackCount FROM Artist JOIN Album ON Artist.ArtistId = Album.ArtistId JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Artist.ArtistId ORDER BY TrackCount DESC LIMIT 5;\"\\n}', name='ask_database')\n",
    "# function (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "710481dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Answer user questions by generating SQL queries against the Chinook Music Database.\n",
      "\u001b[0m\n",
      "\u001b[32muser: Olá, quem sao os 5 artistas com mais músicas?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\\n  \"query\": \"SELECT artists.Name, COUNT(tracks.TrackId) AS TotalTracks FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.Name ORDER BY TotalTracks DESC LIMIT 5;\"\\n}', name='ask_database')\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\u001b[0m\n",
      "\u001b[32muser: Qual a música do Metallica que aparece em mais álbuns?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\\n  \"query\": \"SELECT tracks.Name, COUNT(DISTINCT albums.AlbumId) AS NumAlbums FROM tracks JOIN albums ON tracks.AlbumId = albums.AlbumId JOIN artists ON albums.ArtistId = artists.ArtistId WHERE artists.Name = \\'Metallica\\' GROUP BY tracks.Name ORDER BY NumAlbums DESC LIMIT 1;\"\\n}', name='ask_database')\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [('Whiskey In The Jar', 1)]\n",
      "\u001b[0m\n",
      "\u001b[32muser: Qual são os albuns do Metallica e suas músicas?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\\n  \"query\": \"SELECT albums.Title AS Album, tracks.Name AS Track FROM albums JOIN tracks ON albums.AlbumId = tracks.AlbumId JOIN artists ON albums.ArtistId = artists.ArtistId WHERE artists.Name = \\'Metallica\\';\"\\n}', name='ask_database')\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [('Garage Inc. (Disc 1)', 'Free Speech For The Dumb'), ('Garage Inc. (Disc 1)', \"It's Electric\"), ('Garage Inc. (Disc 1)', 'Sabbra Cadabra'), ('Garage Inc. (Disc 1)', 'Turn The Page'), ('Garage Inc. (Disc 1)', 'Die Die My Darling'), ('Garage Inc. (Disc 1)', 'Loverman'), ('Garage Inc. (Disc 1)', 'Mercyful Fate'), ('Garage Inc. (Disc 1)', 'Astronomy'), ('Garage Inc. (Disc 1)', 'Whiskey In The Jar'), ('Garage Inc. (Disc 1)', \"Tuesday's Gone\"), ('Garage Inc. (Disc 1)', 'The More I See'), ('Black Album', 'Enter Sandman'), ('Black Album', 'Sad But True'), ('Black Album', 'Holier Than Thou'), ('Black Album', 'The Unforgiven'), ('Black Album', 'Wherever I May Roam'), ('Black Album', \"Don't Tread On Me\"), ('Black Album', 'Through The Never'), ('Black Album', 'Nothing Else Matters'), ('Black Album', 'Of Wolf And Man'), ('Black Album', 'The God That Failed'), ('Black Album', 'My Friend Of Misery'), ('Black Album', 'The Struggle Within'), ('Garage Inc. (Disc 2)', 'Helpless'), ('Garage Inc. (Disc 2)', 'The Small Hours'), ('Garage Inc. (Disc 2)', 'The Wait'), ('Garage Inc. (Disc 2)', 'Crash Course In Brain Surgery'), ('Garage Inc. (Disc 2)', 'Last Caress/Green Hell'), ('Garage Inc. (Disc 2)', 'Am I Evil?'), ('Garage Inc. (Disc 2)', 'Blitzkrieg'), ('Garage Inc. (Disc 2)', 'Breadfan'), ('Garage Inc. (Disc 2)', 'The Prince'), ('Garage Inc. (Disc 2)', 'Stone Cold Crazy'), ('Garage Inc. (Disc 2)', 'So What'), ('Garage Inc. (Disc 2)', 'Killing Time'), ('Garage Inc. (Disc 2)', 'Overkill'), ('Garage Inc. (Disc 2)', 'Damage Case'), ('Garage Inc. (Disc 2)', 'Stone Dead Forever'), ('Garage Inc. (Disc 2)', 'Too Late Too Late'), (\"Kill 'Em All\", 'Hit The Lights'), (\"Kill 'Em All\", 'The Four Horsemen'), (\"Kill 'Em All\", 'Motorbreath'), (\"Kill 'Em All\", 'Jump In The Fire'), (\"Kill 'Em All\", '(Anesthesia) Pulling Teeth'), (\"Kill 'Em All\", 'Whiplash'), (\"Kill 'Em All\", 'Phantom Lord'), (\"Kill 'Em All\", 'No Remorse'), (\"Kill 'Em All\", 'Seek & Destroy'), (\"Kill 'Em All\", 'Metal Militia'), ('Load', \"Ain't My Bitch\"), ('Load', '2 X 4'), ('Load', 'The House Jack Built'), ('Load', 'Until It Sleeps'), ('Load', 'King Nothing'), ('Load', 'Hero Of The Day'), ('Load', 'Bleeding Me'), ('Load', 'Cure'), ('Load', 'Poor Twisted Me'), ('Load', 'Wasted My Hate'), ('Load', 'Mama Said'), ('Load', 'Thorn Within'), ('Load', 'Ronnie'), ('Load', 'The Outlaw Torn'), ('Master Of Puppets', 'Battery'), ('Master Of Puppets', 'Master Of Puppets'), ('Master Of Puppets', 'The Thing That Should Not Be'), ('Master Of Puppets', 'Welcome Home (Sanitarium)'), ('Master Of Puppets', 'Disposable Heroes'), ('Master Of Puppets', 'Leper Messiah'), ('Master Of Puppets', 'Orion'), ('Master Of Puppets', 'Damage Inc.'), ('ReLoad', 'Fuel'), ('ReLoad', 'The Memory Remains'), ('ReLoad', \"Devil's Dance\"), ('ReLoad', 'The Unforgiven II'), ('ReLoad', 'Better Than You'), ('ReLoad', 'Slither'), ('ReLoad', 'Carpe Diem Baby'), ('ReLoad', 'Bad Seed'), ('ReLoad', 'Where The Wild Things Are'), ('ReLoad', 'Prince Charming'), ('ReLoad', \"Low Man's Lyric\"), ('ReLoad', 'Attitude'), ('ReLoad', 'Fixxxer'), ('Ride The Lightning', 'Fight Fire With Fire'), ('Ride The Lightning', 'Ride The Lightning'), ('Ride The Lightning', 'For Whom The Bell Tolls'), ('Ride The Lightning', 'Fade To Black'), ('Ride The Lightning', 'Trapped Under Ice'), ('Ride The Lightning', 'Escape'), ('Ride The Lightning', 'Creeping Death'), ('Ride The Lightning', 'The Call Of Ktulu'), ('St. Anger', 'Frantic'), ('St. Anger', 'St. Anger'), ('St. Anger', 'Some Kind Of Monster'), ('St. Anger', 'Dirty Window'), ('St. Anger', 'Invisible Kid'), ('St. Anger', 'My World'), ('St. Anger', 'Shoot Me Again'), ('St. Anger', 'Sweet Amber'), ('St. Anger', 'The Unnamed Feeling'), ('St. Anger', 'Purify'), ('St. Anger', 'All Within My Hands'), ('...And Justice For All', 'Blackened'), ('...And Justice For All', '...And Justice For All'), ('...And Justice For All', 'Eye Of The Beholder'), ('...And Justice For All', 'One'), ('...And Justice For All', 'The Shortest Straw'), ('...And Justice For All', 'Harvester Of Sorrow'), ('...And Justice For All', 'The Frayed Ends Of Sanity'), ('...And Justice For All', 'To Live Is To Die'), ('...And Justice For All', 'Dyers Eve')]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"Qual são os albuns do Metallica e suas músicas?\"})\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "assistant_message.content = str(assistant_message.tool_calls[0].function)\n",
    "messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content})\n",
    "if assistant_message.tool_calls:\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"tool_call_id\": assistant_message.tool_calls[0].id, \"name\": assistant_message.tool_calls[0].function.name, \"content\": results})\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89073c",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "See our other [notebook](How_to_call_functions_for_knowledge_retrieval.ipynb) that demonstrates how to use the Chat Completions API and functions for knowledge retrieval to interact conversationally with a knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c684b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n",
    "import subprocess\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "client = OpenAI()\n",
    "\n",
    "#######\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n",
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\"system\": \"red\", \"user\": \"green\", \"assistant\": \"blue\", \"function\": \"magenta\"}\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "#######    \n",
    "\n",
    "def open_app(app_name):\n",
    "    if app_name == \"calculator\":\n",
    "        subprocess.run('calc.exe', shell=True)\n",
    "        return 'Abriu calc.exe'\n",
    "    elif app_name == \"word\":\n",
    "        subprocess.run('start winword', shell=True)\n",
    "        return 'Abriu word'\n",
    "    elif app_name == \"powerpoint\":\n",
    "        subprocess.run('start powerpnt', shell=True)\n",
    "        return 'Abriu powerpoint'\n",
    "    elif app_name == \"paint\":\n",
    "        subprocess.run('mspaint.exe', shell=True)\n",
    "        return 'Abriu paint'\n",
    "    elif app_name == \"excel\":\n",
    "        subprocess.run('start excel', shell=True)\n",
    "        return 'Abriu excel'\n",
    "    else:\n",
    "        return \"Aplicativo não reconhecido\", 400\n",
    "    \n",
    "def execute_function_call(message):\n",
    "    if message.tool_calls[0].function.name == \"open_app\":\n",
    "        app_name = json.loads(message.tool_calls[0].function.arguments)[\"app_name\"]\n",
    "        results = open_app(app_name)\n",
    "    else:\n",
    "        results = f\"Error: function {message.tool_calls[0].function.name} does not exist\"\n",
    "    return results\n",
    "\n",
    "#######\n",
    "\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"If the user wants to do calculations, respond 'calculator'. For creating documents, respond 'word'. \n",
    "       For presentations, respond 'powerpoint'. For drawing or painting images, respond 'paint. For creating spreadsheets, respond 'excel'\"\"\"\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"open_app\",\n",
    "            \"description\": \"\"\"If the user wants to do calculations, respond 'calculator'. For creating documents, respond 'word'. \n",
    "       For presentations, respond 'powerpoint'. For drawing or painting images, respond 'paint. For creating spreadsheets, respond 'excel'\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"app_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"word\", \"powerpoint\", \"calculator\", \"excel\", \"paint\"],\n",
    "                        \"description\": \"The application the user wants to open\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"app_name\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "#######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee492b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9FCPpMAPZgVBUl4z2USg8KYs7oJFL', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pyNccWRrdHyVsS3SmvGmVQaL', function=Function(arguments='{\"app_name\":\"calculator\"}', name='open_app'), type='function')]))], created=1713409673, model='gpt-3.5-turbo-1106', object='chat.completion', system_fingerprint='fp_ad2b9c6e11', usage=CompletionUsage(completion_tokens=15, prompt_tokens=201, total_tokens=216))\n"
     ]
    }
   ],
   "source": [
    "# # Exemplo de como construir a mensagem de sistema para orientar o modelo\n",
    "# system_message = {\n",
    "#     \"role\": \"system\",\n",
    "#     \"content\": \"\"\"If the user wants to do calculations, respond 'calculator'. For creating documents, respond 'word'. For presentations, respond 'powerpoint'.\"\"\"\n",
    "# }\n",
    "# # Adicionando a mensagem de sistema aos diálogos\n",
    "# messages = [system_message, {\"role\": \"user\", \"content\": \"I want to make a presentation\"}]\n",
    "# messages = [system_message, {\"role\": \"user\", \"content\": \"I want to write\"}]\n",
    "# messages = [system_message, {\"role\": \"user\", \"content\": \"I want to do math\"}]\n",
    "\n",
    "# # Chamada da função\n",
    "# chat_response = chat_completion_request(messages, tools=tools, model='gpt-3.5-turbo-1106')\n",
    "# print(chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f80057de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_app('word')\n",
    "#tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d86a6eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32muser: Quero fazer uma planilha\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\"app_name\":\"excel\"}', name='open_app')\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (open_app): Abriu excel\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "#### INPUT + REQUEST ####\n",
    "#messages.append({\"role\": \"user\", \"content\": \"I want to make a presentation\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Quero fazer uma planilha\"})\n",
    "chat_response = chat_completion_request(messages, tools=tools, model='gpt-3.5-turbo-1106')\n",
    "\n",
    "#visualizar função construída (nas mensagens)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "assistant_message.content = str(assistant_message.tool_calls[0].function)\n",
    "messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content}) \n",
    "\n",
    "#chamada da função\n",
    "if assistant_message.tool_calls:\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"tool_call_id\": assistant_message.tool_calls[0].id, \"name\": assistant_message.tool_calls[0].function.name, \"content\": results})\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9b89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8860bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
